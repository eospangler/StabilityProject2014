\documentclass[12pt]{article}
\pagenumbering{arabic}
\pdfpagewidth 8.5in
\pdfpageheight 11in
\setlength\topmargin{0in}
\setlength\headheight{0in}
\setlength\headsep{0in}
\setlength\textheight{9.0in}
\setlength\textwidth{6.5in}
\setlength\oddsidemargin{0in}
\setlength\evensidemargin{0in}
\setlength\parindent{0.25in}
\setlength\parskip{0.25in}
\parskip 0.0pt
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{tabularx,ragged2e,booktabs,caption}
\usepackage{float}
\usepackage{dcolumn}
\usepackage{natbib}



\begin{document}  


\begin{titlepage}




\title{Let Them Tweet Cake: Estimating Political Stability using Twitter}



\author{Ethan Spangler\thanks{Corresponding Author. Email: {\href{mailto:ethan.spangler@wsu.edu}{ethan.spangler@wsu.edu}}; Tel: 801-458-9923; Washington State University School of Economic Sciences Hulbert Hall 101, Pullman, WA 99164, United States}  \\
Ben Smith\thanks{Email: {\href{mailto:bosmith@unomaha.edu}{bosmith@unomaha.edu}}; University of Nebraska-Omaha Mammel Hall, Suite 332, 6708 Pine Street, Omaha, NE 68182, United States}}



\date{\today}

\maketitle

\begin{abstract}
\noindent Traditional methods of estimating political stability have been unreliable, unable to adapt quickly to the realities on the ground. Thus it is the goal of this paper to create a new measure of political stability, one with a firm theoretical foundation and utilizes advances in social media. Twitter is a micro-blogging website that allows users to post short messages (tweets) that can be viewed and shared by other users, creating a vast network of freely and easily observable information. We collect tweets containing specified words or phrases voicing dissatisfaction with their government. Collected tweets are then scored and aggregated; forming the basis of the measure. Combining these estimates of aggregated dissent with macroeconomic data of the country within an established theoretical framework, we obtain an overall estimation of a country's political stability. A case study focusing on Canada and Kenya, provides proof of concept.
\end{abstract}

\noindent \textit{Keywords}: Twitter, Political Stability, Dissent \\

\noindent \textit{JEL Code}: C80, O57, P16




\end{titlepage}





\begin{spacing}{1.5}

\section*{Introduction}

The importance of political stability is well established and can affect all aspects of an economy (Kaufmann et al. 1999b), substantially impeding economic growth (Alesina and Perotti, 1996; Jong-A-Pin, 2009; Aisen and Veiga, 2013). Additionally, there is a propensity for a country's political stability issues to leak beyond its borders, negatively affecting neighboring nations' stability and creating large scale welfare implications. However, despite its significance, measurement of political stability has remained underdeveloped. 

As demonstrated by the recent uprisings in the Middle East, Thailand, and Ukraine; large scale political changes are difficult to predict. The three commonly used measures of political stability are Political Risk Services (PRS), the Business Environment Risk Intelligence Index (BERI), and the Economist Intelligence Unit (EIU). Each of these indexes combine political, financial, and economic factors to assess a nation's political stability (Howell, 1998). The financial and economic portions are predominately based on quantitative data (foreign debt, inflation, GDP per capita, etc) while political factors are more qualitative in determination. 

Political factors for each index are determined and scored by panels of experts (Howell, 1998). These experts are usually former diplomats, scholars, and other suitably qualified individuals. While these teams of experts can be quite large and knowledgeable, it is still a relatively small group of people trying to assess an entire nation. Additionally these experts lack a clear theoretical foundation for their decisions. 

Since political factors compose 33-66\% of each index (Howell, 1998), if these experts are somehow misinformed the validity of the index could be greatly affected. In turn this potential bias would affect all research based on these indexes. Additionally, over a twenty year study Tetlock (2005) was able to show that political forecasts based on expert opinion were only marginally better than random chance. It becomes quite apparent that a new method of assessing political stability is needed.  

To highlight the issue of why a more robust measure of political stability is needed let us examine some contemporary examples and their related political stability analysis. The October 2005 PRS report on Thailand said ``unrest is not expected to threaten general stability, nor intensify to the point of endangering the [Thai Rak Thai Party's (TRT)] dominant political position...the chances of the TRT being forced from power at any point during the five year forecast period are slim..." (PRS 2006, p. 40). Less than a year later a military coup ousted the Prime Minister Shinawatra and outlawed his TRT party, and began a period of political strife that continues to plague Thailand. The PRS report on Ukraine published October 2012, stated that ``a repeat of the Orange Revolution...is unlikely." and ``Ukrainians are disillusioned but in general they possess little appetite for protest." (PRS 2013, p. 11) Mass protests began in November 2013 and by February 2014 the Yanukovych regime had fallen. The PRS report on Tunisia, published October 2010, called Tunisia an ``oasis of stability" (PRS 2011, p. 3) and postulated a 85\% probability that Tunisian dictator Ben Ali would retain power for the next 18 months. By January 2011, mass protests and revolt resulted in the dissolution of the ruling RCD party, the exile of Ben Ali to Saudi Arabia, and the establishment of an interim government. While it may be easy to critique these forecasts with the benefit of hindsight, these examples highlight the inherent difficulty in predicting something as opaque and complex as political stability.\footnote{It should be noted that PRS publishes monthly reports on its surveyed countries but those are only available to its subscribers.} 

A shared limitation of previous political stability measurements was a lack of both a theoretical framework and quality data. Thankfully, advancements in both areas have arisen that substantially mitigate these issues. Spangler and Smith (2017) establish a theoretical framework for understanding political stability. Spangler and Smith base their theory on the interactions of a government and its citizens; the central premise being that public dissent and political stability have a dynamic relationship. Regarding data, the spread of social media platforms such as Twitter and development of text analysis techniques means that researchers can tap into the zeitgeist of a population like never before. 

In this paper we use online political dissent against a government as a basis for examining a country's political stability. Whereas previous measures of political stability relied on expert opinion, polling, or other traditional methodology; this paper seeks to develop a measure of political stability based on data collected from Twitter. The following sections of this paper will review literature concerning measuring political stability and other relevant topics, theoretical model, explanation of the methodology employed in this paper, proof of concept case studies using Canada and Kenya, and finally conclusion. 

\section*{Related Literature}   

We have already discussed the predominant methods measuring political stability (Howell 1998) and their potential flaws, but there are other methods that need to be addressed. Kaufmann et al. (1999a) proposes using 'aggregate governance indicators' which combines hundreds of different variables and indicators (including those built by PRS, BERI, and EUI) together to evaluate several factors of governmental quality to get the most out of available data. Jong-A-Pin (2009) uses a similar multi-dimensional approach to evaluate the economic impact of political stability. This approach does work to smooth out some of the issues of a single indicator but ultimately Kaufmann et al. concludes that contemporary methods "point to the inadequacy of existing governance measures." (Kaufmann et al., 1999a p. 31). Other methods of evaluating government effectiveness rely on crowd souring, polling, and surveying; but all have their own limitations. 

Ungar et al. (2012) relies on expert opinion, but instead of just a few experts Ungar et al. employ thousands, using a mixture of crowd sourcing and simplification of complex issues. Ungar et al.'s approach works by having their army (over 2000 individuals) of forecasters assign probability estimates to specific events happening within a given time (Q:``Will Julius Caesar cease power before March 15\textsuperscript{th}?", A: Yes, 42\% probability.), updating their predictions as needed before the deadline. Finally, all predictions are combined to form a single aggregate forecast of the event. 

Ungar et al.'s method, and prediction markets in general, are extremely effective in harnessing the wisdom of crowds, but at the same time they are hamstrung by the simplifications needed in order to harness that wisdom. They work best when asking the crowd simple questions, which may not capture all the nuances and complexities necessary to understand an issue, especially when attempting to gauge a country's overall political stability. Additionally, in dealing with esoteric issues, there might only be a few experts with area knowledge, which leaves this method vulnerable to the same problems as described earlier (Tetlock, 2005). Finally, maintaining and incentivizing a vast number of forecasters is likely very costly and time intensive, as one must wait for forecasters to make and adjust their judgements. 

Polling and survey are also costly and time consuming, but they have their own unique issues as well that are difficult for researchers to overcome. The biggest hurdle is one of honesty since respondents often have little incentive to be honest, to varying degrees of malevolence. One issue is the `social desirability bias', wherein respondents have a tendency to provide what they perceive to be the socially acceptable answer to questions regardless of how they actually feel on the issue (Setphens-Davidowitz, 2017). This especially could be an problem if someone is being asked about popular government entities or policies they are in the opposition to. 

The issue is further intensified by the fact that many places where accurate measurement of political stability is most needed, might also be places where honest public speech is not safe. According to Freedom House (2017), of the 195 countries evaluated, only 44\% were regarded as `free' in regards to political rights. This means that in most countries a person might be unwilling to provide their honest thoughts to a stranger asking about their government. On the other extreme, respondents may provide strategic answers with the intent of influencing potential policy that may be based on poll results, biasing results (Morgan and Stocken, 2008). Finally, results could be biased because respondents provide false information purely for their own trollish amusement (Setphens-Davidowitz, 2017). Fortunately, the rise of the internet and associated social media platforms has provided a wealth of new data that helps overcome the problems of previous methods. 

%need some better bridge...
\subsection*{Twitter Literature}

One social media platform that has proven to be especially useful to researchers is Twitter. Twitter is a micro-blogging website that allows users to post short messages (tweets) that can be viewed and shared by other users. These posts can also include tags that allow users to link posts with a common theme. All of this creates a vast network of information that can be freely and publicly observed. With a current active monthly user base of over 300 million people (Twitter, 2016) spread across the world, all sharing their opinions and thoughts on a myriad of topics, there is vast potential for this data source. 

Twitter data has already shown to be useful in several areas, often performing better than traditional data sources. Asur and Huberman (2010) were able to use Twitter chatter to predict film box office returns better than the industry standard. Bollen et al. (2011) show that Twitter data can be used to forecast stock market fluctuations. Smith and Wooten (2016) shows that people use Twitter as a sources of information and were able to estimate demand for this information. In terms of politics, O'Conner et al. (2010) and Lampos et al. (2013) use Twitter as a more accurate source for political forecasting. 

There is also interesting research concerning issues of political stability using Twitter data. Carly et al. (2013) find that Twitter chatter increases as large scale political events unfold. Carly et al. demonstrates that there is a very real connection between real world and online behavior, people are tweeting in response to things that are happening in life. This point is further reinforced by research suggesting that Twitter can be used in protest recruitment (Gonz{\'a}lez-Bail{\'o}n et al., 2011) and attempts to predict protest participation (Kallus, 2014). This line of research has been deemed so promising that the US Department of Defense has funded several ongoing projects in this area (Minerva Initiative, 2014).  

This paper adds to the work on political stability by attempting to build a empirical measure of political stability. The core of this measure is based on Twitter data but also supported by macroeconomic data. By examining Twitter data directly, we mitigate many of the issues of other measures of political stability that rely heavily on expert opinion, polls, or surveys. Also, by combining our measure with macroeconomic data, we can get a much broader picture of a country's political stability than previous street level Twitter studies and allow for cross country analysis using the same methodology. Overall we feel that this is an approach that could greatly aid in assessing which countries are at risk of governmental failure, before reaching the headlines.      

\section*{Theory}

%Twitter post as expressing a demand for dissent. Why is there demand for dissent -> governmental inadequacy 

The central premise of this paper is that people use online platforms, specifically Twitter, to kvetch about politics and express dissent against their government. Previous methods of evaluating governmental quality generally tried to find some quantifiable way to evaluate government institutions. Instead, we are interested in the public's perceptions of these institutions. A well functioning government should be like air, if it's working well, no one will talk about it. The idea is that the more dysfunctional a government and its institutions are, the more demand there will be for dissent against the government.

The theoretical foundation for demand for dissent is from Spangler and Smith (2017), wherein a non-altruistic government and its citizens dynamically interact. The government maximizes its own stability, $\Lambda_t$, by choosing its level of public services, $G_t$, and security, $S_t$, allotments subject to a resource constraint, $R_t$, and total dissent from the citizenry, $D_{t-1}$. In turn, each member of the public maximizes their utility by choosing their level of dissent, $d_{i,t}$, based on their own preferences and the risk of punishment. 

\vspace{.5 em}

\noindent Government's problem:
\begin{equation}
{\underset{G_t,S_t}{\text{max }}} \sum\limits_{t=1}^{T^*} \beta^t {\Lambda}_t = \sum\limits_{t=1}^{T^*} \beta^t\left(\frac{G_t}{D_{t-1}}-\Phi\right)^\alpha \left(\frac{S_t}{D_{t-1}}-\Omega\right)^\gamma   \text{s.t. } G_t+S_t=R_t
\end{equation}

The government chooses it's allocations of $G_t$ and $S_t$ based on its preferences for each, $\alpha$ and $\gamma$ respectively. A minimum amount of resources must be allocated to $G_t$ and $S_t$ to avoid anarchy, denoted by $\Phi$ and $\Omega$. This function is optimized across time to $T_*$, the inevitable point of eventual state failure, and discounted at rate $\Beta$.  

The source of instability is the bureaucratic lag between periods, since the government responds to the total dissent from the previous period $D_{t_1}$ while citizens react to the current period. When, $D_t \approx D_{t-1}$, there is minimal instability. However, when $D_t \not\approx D_{t-1}$ the situation can spiral out of control and result in governmental failure. 

\vspace{.5 em}
\noindent Individual's Problem:
\begin{equation}
{\underset{d_{i,t}}{\text{max }}}  U_{i,t}= \frac{{d_{i,t}}^{{x}_i}}{g_t * E} - P_t \left( \bar{d}_{t-1} \Bigg|\frac{D_{t-1}}{S_t},\sigma \right)d_{i,t}^A
\end{equation}

An individual's utility from dissent, $U_{i,t}$, is a function of their individual activism preference, $x_i$, which is distributed $LogN(0,1)$. For some values of $x_i$ an individual will would actually receive disutility from dissent, so they elect not to, $d_{i,t}=0$. Higher values of $x_i$ mean that the individual receives utility from dissenting, $d_{i,t}>0$. This heterogeneity amongst the population means that each period for given policy choices ($G_t$,$S_t$) there is a spread of people that do not dissent and variation in the level of dissent among those that do.  

The benefits and services the individual receives from the government is $g_t$, with $g_t=\frac{G_t}{N_t}$ and $N_t$ is total population, their quality of life, $E$, the probability of being caught dissenting, $P_t$, and the severity of punishment for dissenting, $A$. $P_t$ the log-Normal PDF and is determined by average individual dissent from the previous period, $\bar{d}_{t-1}$, the ratio of previous total dissent to security allocations, $\frac{D_{t-1}}{S_t}$, and policing effectiveness, $\sigma$. 

Maximization of individual utility w.r.t. to $d_{i,t}$ yields $d_{i,t}^*$, individual demand for dissent.  

\vspace{.5 em}
\begin{equation}
d_{i,t}^*=& \left(\frac{g_tEP_t A}{x_i} \right)^{\frac{1}{x_i -A}}
\end{equation}

Individual's demand for dissent is a reflection of perceived governmental quality. Everyday individuals face societal issues they themselves cannot overcome but these issues negatively affect their life. These are issues such as crime, corruption, and other societal issues that only a government could properly address, but for whatever reason the government is unable to address sufficiently for the individual. The simultaneous frustration with governmental expectations and the inability to do anything about the issues themselves, leads the individual to do the only thing they can do, dissent. Dissenting provides a cathartic release for the individual, making them feel slightly better.

%To find the expected total dissent, we integrate ${d_{i,t}}^*$ times the PDF of $x_i$, which is $LogN(0,1)$, across the relevant range of $x_i$, $0$ to $x_{max}$, will give the average amount of dissent per capita in a country. Multiplying this by the population, $N_t$, gives the expected total dissent, $D_t$.

Integrating ${d_{i,t}}^*$ times the PDF of $x_i$, which is $LogN(0,1)$, with respect to $x_i$ across the relevant range of $x_i$, $0$ to $x_{max}$, provides the average amount of individual dissent in a country. Multiplying this by the population, $N_t$, generates expected total dissent, $D_t$. 

\begin{equation}
D_t	=& N_t \int_{0}^{x_{max}} {{d}_{i,t}}^* \frac{1}{x \sqrt{2\pi}}exp  \left( -\frac{(lnx)^2}{2\sigma^2} \right)  dx 
\end{equation}

This theoretical model allows for better understanding of how shocks at the governmental and individual level may impact a country’s overall level of political stability. Also, by varying the governmental and individual parameters, cross country comparisons can be done allowing this to be used as the theoretical foundations for a measure of political stability. However, while many of these parameter shocks would not be easily detectable as they happen, we are able to observe the increase in Twitter chatter that would likely accompany such a shock. Thus, by examining how the public expresses anger online, we can see how politically stable a country is. 

\section*{Methodology}

An issue in transitioning from the theoretical model to the empirical model, is how does one acquire an estimate for $D_t$, total dissent. All other variables and parameters can be obtained through existing data or internal estimation. The spread of social media, specifically Twitter, allows us to capture people voicing dissent. A central premise of this project is that digital behavior is representative of physical behavior. This paper follows a similar method as Smith and Wooten (2016) and Carly et al. (2013), but expanded to capture the more open ended nature of political stability. 

%Our process began by forming a codex of words and phrase one would use to express dissent against the government. 

%Our process begins by collecting tweets containing any words from a list we judged to consistent with the language one would use to dissent against the government. 

 %head off potential criticism, give more detail 

Our process began by first forming a list of words consistent with the language one would use to express dissent against the government. The list included words and phrases such as: ``police", ``rule of law", ``corruption", ``molotov", as well as the names of important political figures and institutions in our sample countries, Canada and Kenya. We then collect any tweet containing at least one of our words. Technical limitations bar collect of more than 1\% of all incoming twitter traffic, constraining the amount of target words we would be able to collect from. Additionally, the majority of tweets are sent though mobile devices (Twitter, 2016) and this general location information is collected along with the tweet. 

While by no means exhaustive, the goal was to collect as many tweets as possible that might express dissent against the government. The authors of this paper do not claim to be experts on either Canada or Kenya, but extensive research and care was taken to ensure that the collection list reflected the contemporary political landscape of each country. Data collection of tweets containing words from our predetermined list began June 2016 and ran to September 2016, obtaining millions of tweets.

%(THE DATES OF DATA COLLECTION! and how many tweets from our COUNTRIES OF INTEREST were captured). 

The next step is to run our collected tweets through regular expressions, which allows us to go beyond a simple word count but instead account for the context of the tweet. Each regular expression is scored on a scale of 1 to 5, with 1 being low dissent and 5 being high dissent. Controlling for context using regular expressions is important because some words have different cultural meanings that might create bias if only a simple word count was employed. 

For example, one of our code words is `anarchy' and in Kenya it is used in the very traditional style of discussing issues involving lack of government and lawlessness. However, in Canada the vast majority of tweets containing `anarchy' were discussing the TV show \textit{Sons of Anarchy}, which is not relevant to our purposes. The potential for bias is why single word count scores were used very sparingly in this paper. Single word counts were only used when collecting tweets in languages other than English (Swahili and French) or with very specific terms used in only a negative context (e.g. `nairobbery'). The issue of translation should be minimal since in both Canada (Poblete et al., 2011) and Kenya (The Economist, 2014) the predominant language of choice on Twitter is English. 

A single Tweet can be scored multiple times, depending on its contents. The more expressive a tweet, the more an individual is dissenting. Take this example tweet: 

\vspace{.5 em}
(example tweet here.)     

\noindent This tweet would be scored by the following regular expressions:
\vspace{.5 em}
\\
(Which regexes that we used and their score)  

%our time interval

%a plot of total angry tweets in each country, broken down by week. 

The final score of this tweet would be (A NUMBER). The final score of a tweet is an individual's estimated $\hat{d_{i,t}}$. Individual scores are aggregated weekly to form estimates of total dissent in a country, $\hat{D_t}$. The end result is a estimate of public dissent that lets us know what people are angry about, to what degree, and where. 

While previous work used various measures and proxies to assess government institutional quality, many of those measures have the same subjectivity problem as the political stability measures discussed previously or can only be used ex-post. By focusing on dissent and weighting it by quantitative data we can get a more accurate view of institutional quality by looking at how frustrated people are with these institutions. 

%Save for the conclusions 

A possible criticism of this analysis is that even with our regular expressions we are not able to fully control and quantify the tone of a tweet. For example, how do we deal with sarcasm. To answer this potential criticism, we feel that any tweet containing a political message, even one clearly satirical in nature, does not happen in a vacuum. The tweet authors have encountered something in their life that causes them to respond. The fact that they've responded sarcastically is just a choice of phrasing and is inconsequential for our purposes. It only matters that they posted the tweet. The same logic can also be applied to people tweeting in defense of their government and institutions. Again, this is not happening in a vacuum; these people are reacting to something and we are capturing that in their tweet.   

%might save this for the conclusions 

Another critique is that by using social media data, we have inherent bias because these platforms tend to have a younger user base. This is certainly the case with Twitter users in Canada (Insights West, 2016) and Kenya (Simon et al., 2014), where the average Twitter user is in their twenties. However, Rothchild (2015) shows that a properly statistically weighted non representative sample can still be effective for poll forecasting. Additionally, this potential bias may even be an asset that enhances our measure. The demographic group most likely to use social media, the young, are also the most likely to advocate for large scale political change. Thus by forming the basis of our measure on dissent on social media, we're actually able to account for the group most likely to take to the streets.

\subsection*{Case Studies: Canada and Kenya}

Two sample countries were selected as case studies to provide proof of concept: Canada and Kenya. Each country was selected for their similarities and differences. First, both countries use English as their primary language, especially online. Having a shared language significantly reduces the potential for misidentification that translation would entail. Second, there are different a priori expectations of each’s political stability. Canada is a developed country that often ranks amongst the top of nations in terms of development, citizen happiness, and governmental transparency. Conversely, Kenya is a developing country with a history of political instability, corruption, and ethnic tension. Most notable, the substantial post election violence in 2007 following the election of former Kenyan President Mwai Kibaki. This unrest resulted in the deaths of 1,200 people and displaced of hundreds of thousands of others (Blair, 2016). Our measure of political stability should be robust enough to account for the substantial differences between the two.  Finally and most importantly, the populations of each country are prolific users of Twitter. In Canada there are over 7 million monthly active users on Twitter (Statista, 2017). In Kenya, there are an estimated 700 thousand monthly active users (Kemibaro, 2014). This means that Twitter provides an easy way of surveying the political moods of large sections of the Canadian and Kenyan populations. 

%How many unique users did we get during that time period? 



%find population density maps 

%get the peripheral data: G, S, GDP, Crime data. 


%cost associated with created a tweet 

%How do you quantify that level of complaining 

%How do we deal with re-tweets 
  \section*{Estimation}   

(Work in progress)

\section*{Conclusion}

What we have presented in this paper is not designed as a replacement for traditional means of measuring political stability. Instead, it is meant as an enhancement. Knowing what expressions people use for expressing dissent and how to properly judge the validity of those statements still requires an expert's knowledge and opinion. However, using this framework would help mitigate the subjective nature of interpreting political stability. 


%Critique- while this method of estimating political stability is highly contingent upon the the social media population. However, smart phone usage is rising across the world (Poushter, 2016) and with it social media usage. 

%Manipulation by outside forces (bot armies) 

%China's manipulation of social media (King, 2016). 

\end{spacing}

\pagebreak

\bibliographystyle{chicago}
\bibliography{Twitter_Bibli}

\nocite{*}



\end{document}	

